{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8187268",
   "metadata": {},
   "source": [
    "# Predicting Gender in Sinhala Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0c010",
   "metadata": {},
   "source": [
    "When using Sinhala names to predict gender, it is necessary to identify the best number of indicators that should be used and how these indicators are represented. In this particular implementation classifiers are trained with varying number of features/indicators(last letter, last two letters, and last three letters). When representing each of these features/indicators, it is assumed that each sinhala letter can be represented using two unicode characters, vowel or consonant followed by a diacritic. Where the value of the diacritic is set to zero if a diacritic is not present after a word.\n",
    "\n",
    "> letter = ( vowel or consonant, diacritic )\n",
    "\n",
    "Unicode representation(decimal) of sinhala characters range as follows, \n",
    "\n",
    "> 3457 < Vowels and Consonants < 3527 < Diacritics < 3573\n",
    "\n",
    "Using this approach, if the last two letters are considered when predicting the gender, the set of features will contain four features and the values of these features will be the decimal value of their respective unicode representation. \n",
    "\n",
    "The main drawback of this approach is that some letters will not be well represented. For example if we consider the word 'ප්‍රමෝද්‍යා', the last two characters are represented by \\[3503, 3530, 8205, 3514, 3535\\]. The first two characters represent 'ද්', the last two characters represent 'යා', and the third character is out of the unicode range. When extracting letters/features, in the implemented approach, out of range unicodes characters are ignored. Therefore the last two characters of 'ප්‍රමෝද්‍යා' will be represented as 'ද්යා' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce93fb",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca310ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import tree                                      # Decision Tree Classifier\n",
    "from sklearn.svm import SVC                                   # Support Vector Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier           # Random Forest Classifier\n",
    "from sklearn.linear_model import LogisticRegression           # Logistic Regression model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d03a29",
   "metadata": {},
   "source": [
    "## Implementing support functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f8a56",
   "metadata": {},
   "source": [
    "The following support functions are used to extract and represent features from sinhala letters. \n",
    "\n",
    "The ```is_letter()``` function determines if a given character is a sinhala vowel or a consonant by comparing its unicode value with the range of sinhala unicode values. Similarly the ```in_range()``` function is used to determine if a given unicode character is within the range of sinhala characters(consonent, vowel, ordiacritic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b30ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinhala vowels and consonents start at unicode 3457 (decimal)\n",
    "vowels_and_consonants_start = 3457\n",
    "# Sinhala vowels and consonents end at unicode 3527\n",
    "vowels_and_consonants_end = 3527\n",
    "# Sinhala characters end at 3573\n",
    "sinhala_end = 3573\n",
    "\n",
    "# If the character is a sinhala vowel or a consonant True is returned\n",
    "def is_letter(letter):\n",
    "    if vowels_and_consonants_start <= ord(letter) <= vowels_and_consonants_end:\n",
    "        return True\n",
    "    \n",
    "# If the charcter is in the sinhala unicode range True is returned\n",
    "def in_range(letter):\n",
    "    if vowels_and_consonants_start <= ord(letter) <= sinhala_end:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3eb712",
   "metadata": {},
   "source": [
    "The ```generate_feature()``` function creates a feature representation of a given name. The function takes the **name** and the **number of features** as inputs to the function and characters are extracted from the end of the name depending on the number of features required. As per the design of this method, the length of the feature list is going to be 2 times the number of extracted letters(each letter is represented by 2 unicode characters).\n",
    "\n",
    "The function returns a feature list, representing the last n characters of the name.\n",
    "\n",
    "Given a name, the function scan the name in reverse order. As each letter is represented by two unicode characters as \\[vowel/consonant, diacritic\\], position of the diacritic is divisible by two and the position of the vowel/consonant is not divisible by two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c7fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature(name, no_of_features):\n",
    "    # stores the extracted feature list \n",
    "    feature = list()\n",
    "    \n",
    "    # Count is used to determine the character type(vowel/consonant or diacritic)\n",
    "    count = 0\n",
    "    # Name is scanned in the reverse order\n",
    "    for character in reversed(name):\n",
    "        # if the character is a sinhala vowel/consonant and count is divisible by zero,\n",
    "        # then there is no diacritic present in the letter. Therefore the diacritic is set to zero\n",
    "        # by appending zero to the feature list first and then the unicode of the given letter is appended\n",
    "        # count is increased by 2 to point to the dicritic of the next letter.\n",
    "        if is_letter(character) and count%2 == 0:\n",
    "            feature.append(0)\n",
    "            feature.append(ord(character))\n",
    "            count += 2\n",
    "        # if the character is a sinhala vowel/consonant and count is not divisible by zero,\n",
    "        # then the unicode of the character is appended to the feature list directly\n",
    "        elif is_letter(character) and count%2 != 0:\n",
    "            feature.append(ord(character))\n",
    "            count += 1\n",
    "        # If the character is a diacritic then it is appended to the feature list directly\n",
    "        elif is_letter(character) == None and in_range(character):\n",
    "            feature.append(ord(character))\n",
    "            count += 1\n",
    "        \n",
    "        # if the count reaches the number of required features x 2 (each letter is represented by 2 characters)\n",
    "        # the process is halted\n",
    "        if count == no_of_features*2:\n",
    "            break\n",
    "           \n",
    "    # the created list is in reverse order so it is revered before returning \n",
    "    return list(reversed(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca010f95",
   "metadata": {},
   "source": [
    "The feature vector extracted from the last 2 letters of the word 'ප්‍රමෝද්‍යා' is represented as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2a3637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3503, 3530, 3514, 3535]\n"
     ]
    }
   ],
   "source": [
    "print(generate_feature('ප්‍රමෝද්‍යා', 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc0fbc",
   "metadata": {},
   "source": [
    "## Creating the Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88be7586",
   "metadata": {},
   "source": [
    "Initially, ```male.txt``` and ```female.txt``` are read as csv and an extra column is added to represent the relavant label ```male``` or ```female```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8553eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 2)\n",
      "(211, 2)\n"
     ]
    }
   ],
   "source": [
    "# reading the files\n",
    "male = pd.read_csv(\"data/male.txt\", names=['name'], encoding='utf8')\n",
    "female = pd.read_csv(\"data/female.txt\", names=['name'], encoding='utf8')\n",
    "\n",
    "# adding label column\n",
    "male['gender'] = 'male'\n",
    "female['gender'] = 'female'\n",
    "\n",
    "print(male.shape)\n",
    "print(female.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8a376",
   "metadata": {},
   "source": [
    "The two separate dataframes(male and female) are combined to create a single dataframe and samples are shuffled to randomize them. The created dataframe contains 457 samples with 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a230448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Dataframe:  (457, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>කෞෂල්‍ය</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>දිනේෂ්ෂාන්</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>හසිනි</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>වසන්ති</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ඉඳුවර</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  gender\n",
       "0     කෞෂල්‍ය    male\n",
       "1  දිනේෂ්ෂාන්    male\n",
       "2       හසිනි  female\n",
       "3      වසන්ති  female\n",
       "4       ඉඳුවර    male"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining the dataframes\n",
    "dfs = [male, female]\n",
    "dataframe = pd.concat(dfs)\n",
    "\n",
    "# shuffling the samples\n",
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print('Shape of the Dataframe: ',dataframe.shape)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71091b",
   "metadata": {},
   "source": [
    "## Splitting the Dataframe into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace427e",
   "metadata": {},
   "source": [
    "The dataframe is split into train and test sets with a 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "034f0bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365, 1)\n",
      "(92, 1)\n"
     ]
    }
   ],
   "source": [
    "df = dataframe.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'gender'], \n",
    "                                                    df['gender'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6434aef",
   "metadata": {},
   "source": [
    "## Extracting features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82170f24",
   "metadata": {},
   "source": [
    "The created ```generate_feature()``` function is used to extract the required number of letters from names in train and test sets. The names are replaced with lists of equal length(2 x number of required letters), representing the unicode values(decimal) of given characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4768dc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3522, 0, 3517, 3530, 3514, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3522, 3530, 3522, 3535, 3505, 3530]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3524, 0, 3523, 3538, 3505, 3538]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3523, 0, 3505, 3530, 3501, 3538]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3507, 3540, 3520, 0, 3515, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name\n",
       "0        [3522, 0, 3517, 3530, 3514, 0]\n",
       "1  [3522, 3530, 3522, 3535, 3505, 3530]\n",
       "2     [3524, 0, 3523, 3538, 3505, 3538]\n",
       "3     [3523, 0, 3505, 3530, 3501, 3538]\n",
       "4        [3507, 3540, 3520, 0, 3515, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate_feature() is called on each element using lambda functions and apply method\n",
    "X_train['name'] = X_train['name'].apply(lambda x: generate_feature(x, 3))\n",
    "X_test['name'] = X_test['name'].apply(lambda x: generate_feature(x, 3))\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e64ee",
   "metadata": {},
   "source": [
    "The lists containing features of the names are separated into individual elemets represented by columns in the dataframe. As some names only contain limited number of characters, additional elements of those names will be NaN values. These NaN values are replaced by 0.0 \n",
    "\n",
    "This process is done on both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0b5bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3522.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3517.0</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>3514.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3522.0</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>3522.0</td>\n",
       "      <td>3535.0</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>3530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3524.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3523.0</td>\n",
       "      <td>3538.0</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>3538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>3538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3507.0</td>\n",
       "      <td>3540.0</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3515.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5\n",
       "0  3522.0     0.0  3517.0  3530.0  3514.0     0.0\n",
       "1  3522.0  3530.0  3522.0  3535.0  3505.0  3530.0\n",
       "2  3524.0     0.0  3523.0  3538.0  3505.0  3538.0\n",
       "3  3523.0     0.0  3505.0  3530.0  3501.0  3538.0\n",
       "4  3507.0  3540.0  3520.0     0.0  3515.0     0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating train set list to columns\n",
    "X_train = X_train['name'].apply(pd.Series)\n",
    "# replacing NaN with 0.0\n",
    "X_train = X_train.fillna(0.0)\n",
    "\n",
    "# Separating test set list to columns\n",
    "X_test = X_test['name'].apply(pd.Series)\n",
    "# replacing NaN with 0.0\n",
    "X_test = X_test.fillna(0.0)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9697599",
   "metadata": {},
   "source": [
    "## Model training & making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d505f",
   "metadata": {},
   "source": [
    "The following classifiers are used for the classification process.\n",
    "\n",
    "1. Support Vector Machine\n",
    "2. Decision Tree Classifier\n",
    "3. Random Forrest Classifier\n",
    "4. Logistic Regression\n",
    "\n",
    "Implementation details of each classifier is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862764b4",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d67ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "prediction = svc.predict(X_test)\n",
    "acc = accuracy_score(prediction, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a30da",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3be428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456521739130435"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc = dtc.fit(X_train, y_train)\n",
    "prediction = dtc.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(prediction, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4559cf2",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f7a4006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9782608695652174"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train , y_train)\n",
    "prediction = rfc.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(prediction, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44942ac",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439dd695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7608695652173914"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "prediction = lr.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(prediction, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a019a",
   "metadata": {},
   "source": [
    "## Finding the best classifier-feature combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6506e100",
   "metadata": {},
   "source": [
    "In this section the above code is organized into functions and multiple classifier-feature combinations are tested to derive the best possible combination. The 4 classifiers mentioned above are combines with 3 sets of features(last letter, last 2 letters, last 3 letters) to derive 12 combinations. \n",
    "\n",
    "An in-depth description of the functionality provided by these functions are provided in above sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4fa0f2",
   "metadata": {},
   "source": [
    "The ```get_dataframe()``` function reads the text files as csv using pandas, adds the label column, shuffles the combined dataframes and returns the created dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8be73278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe():\n",
    "    # reading files\n",
    "    male = pd.read_csv(\"male.txt\", names=['name'], encoding='utf8')\n",
    "    female = pd.read_csv(\"female.txt\", names=['name'], encoding='utf8')\n",
    "\n",
    "    # adding label column\n",
    "    male['gender'] = 'male'\n",
    "    female['gender'] = 'female'\n",
    "    \n",
    "    # combining the 2 dataframes\n",
    "    dfs = [male, female]\n",
    "    dataframe = pd.concat(dfs)\n",
    "    \n",
    "    # shuffling samples\n",
    "    dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5254d6ff",
   "metadata": {},
   "source": [
    "The ```convert_names_to_feature()``` function extracts the required number of features/letters from names using the ```generate_feature()``` support function and separate the features into individual elemets represented by columns in the dataframe. This function also replaces the NaN values by 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b015db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_names_to_features(X, no_of_features):\n",
    "    # extracting name features\n",
    "    X['name'] = X['name'].apply(lambda x: generate_feature(x, no_of_features))\n",
    "    \n",
    "    # splitting the list of features into columns\n",
    "    X = X['name'].apply(pd.Series)\n",
    "    # replacing NaN with 0.0\n",
    "    X = X.fillna(0.0)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1722d3",
   "metadata": {},
   "source": [
    "Given a name of a classifier this function initializes the respective classifier and returns it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84eac618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier(name):\n",
    "    if name == 'Decision Tree':\n",
    "        return tree.DecisionTreeClassifier()\n",
    "    elif name == 'Support Vector':\n",
    "        return SVC()\n",
    "    elif name == 'Random Forest':\n",
    "        return RandomForestClassifier()\n",
    "    elif name == 'Logistic Regression':\n",
    "        return LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19786e42",
   "metadata": {},
   "source": [
    "The ```name_gender_classifier()``` function performs the following tasks,\n",
    "\n",
    "1. Extract features from train and test set names using ```convert_names_to_features()```\n",
    "2. Train the classifier passed as input, using train set.\n",
    "3. Make predictions on the test set\n",
    "4. Calculate accuracy, precision, and f1-score and return a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb66981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_gender_classifier(X_train, X_test, y_train, y_test, no_of_features, classifier):\n",
    "    # extracting features\n",
    "    X_train = convert_names_to_features(X_train, no_of_features)\n",
    "    X_test = convert_names_to_features(X_test, no_of_features)\n",
    "    \n",
    "    # Training the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Making predictions\n",
    "    pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Deriving accuracy based on predictions\n",
    "    accuracy = accuracy_score(pred, y_test)\n",
    "    # Deriving precision, recall, f1, support\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_test, pred, average='macro')\n",
    "    \n",
    "    return (accuracy, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4da6f7",
   "metadata": {},
   "source": [
    "The classification is performed for each of the classifier-feature combination using the functions that are defined above. For each of the combination, its accuracy, precision, recall, and F1-score are outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9918d482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature(s): Last letter  Classifier: Decision Tree\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.967391304347826\n",
      "Precision:  0.9625\n",
      "Recall:  0.9727272727272727\n",
      "F1-Score:  0.9665007889306955\n",
      "\n",
      "Feature(s): Last letter  Classifier: Support Vector\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.6630434782608695\n",
      "Precision:  0.7720588235294117\n",
      "Recall:  0.7181818181818181\n",
      "F1-Score:  0.6561784207353828\n",
      "\n",
      "Feature(s): Last letter  Classifier: Random Forest\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.967391304347826\n",
      "Precision:  0.9644249512670565\n",
      "Recall:  0.9683046683046683\n",
      "F1-Score:  0.9662385321100917\n",
      "\n",
      "Feature(s): Last letter  Classifier: Logistic Regression\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.6521739130434783\n",
      "Precision:  0.6862155388471178\n",
      "Recall:  0.6825552825552825\n",
      "F1-Score:  0.6520094562647754\n",
      "\n",
      "________________________________________________________________________________________________\n",
      "\n",
      "Feature(s): last 2 letters  Classifier: Decision Tree\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.967391304347826\n",
      "Precision:  0.9625\n",
      "Recall:  0.9727272727272727\n",
      "F1-Score:  0.9665007889306955\n",
      "\n",
      "Feature(s): last 2 letters  Classifier: Support Vector\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.6630434782608695\n",
      "Precision:  0.7720588235294117\n",
      "Recall:  0.7181818181818181\n",
      "F1-Score:  0.6561784207353828\n",
      "\n",
      "Feature(s): last 2 letters  Classifier: Random Forest\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.9782608695652174\n",
      "Precision:  0.9743589743589743\n",
      "Recall:  0.9818181818181818\n",
      "F1-Score:  0.9775828460038987\n",
      "\n",
      "Feature(s): last 2 letters  Classifier: Logistic Regression\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.8043478260869565\n",
      "Precision:  0.8120550545799715\n",
      "Recall:  0.8230958230958232\n",
      "F1-Score:  0.8035121025154247\n",
      "\n",
      "________________________________________________________________________________________________\n",
      "\n",
      "Feature(s): last 3 letters  Classifier: Decision Tree\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.967391304347826\n",
      "Precision:  0.9625\n",
      "Recall:  0.9727272727272727\n",
      "F1-Score:  0.9665007889306955\n",
      "\n",
      "Feature(s): last 3 letters  Classifier: Support Vector\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.6630434782608695\n",
      "Precision:  0.7720588235294117\n",
      "Recall:  0.7181818181818181\n",
      "F1-Score:  0.6561784207353828\n",
      "\n",
      "Feature(s): last 3 letters  Classifier: Random Forest\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.967391304347826\n",
      "Precision:  0.9625\n",
      "Recall:  0.9727272727272727\n",
      "F1-Score:  0.9665007889306955\n",
      "\n",
      "Feature(s): last 3 letters  Classifier: Logistic Regression\n",
      "-------------------------------------------------\n",
      "Accuracy:  0.6413043478260869\n",
      "Precision:  0.6706349206349207\n",
      "Recall:  0.669041769041769\n",
      "F1-Score:  0.6412619638426089\n",
      "\n",
      "________________________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The list of classifiers\n",
    "classifier_list = ['Decision Tree', 'Support Vector', 'Random Forest', 'Logistic Regression']\n",
    "# List of features\n",
    "feature_list = ['Last letter', 'last 2 letters', 'last 3 letters']\n",
    "features = [1, 2, 3]\n",
    "\n",
    "# Variable to store details of the best classifer-feature combination\n",
    "best_accuracy = 0.0\n",
    "best_classifier = None\n",
    "best_feature = None\n",
    "\n",
    "dataframe = get_dataframe()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataframe.loc[:, dataframe.columns != 'gender'], \n",
    "                                                    dataframe['gender'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    shuffle=False)\n",
    "# Names in test set is saved to identify misclassifications\n",
    "name_list = X_test['name'].copy()\n",
    "\n",
    "# Selecting the best classifier-feature combination\n",
    "for feature in features:\n",
    "    for clf in classifier_list:\n",
    "        X = X_train.copy()\n",
    "        X_t = X_test.copy()\n",
    "        y = y_train.copy()\n",
    "        y_t = y_test.copy()\n",
    "        \n",
    "        # Get the classifier instance using name\n",
    "        classifier = get_classifier(clf)\n",
    "        # Performing classification\n",
    "        accuracy, precision, recall, f1 = name_gender_classifier(X, X_t, y, y_t, feature, classifier)\n",
    "        \n",
    "        # Best combination is selected based on accuracy\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_classifier = classifier\n",
    "            best_feature = feature\n",
    "            \n",
    "        print('Feature(s): {}  Classifier: {}'.format(feature_list[features.index(feature)], clf))\n",
    "        print('-------------------------------------------------')\n",
    "        print('Accuracy: ', accuracy)\n",
    "        print('Precision: ', precision)\n",
    "        print('Recall: ', recall)\n",
    "        print('F1-Score: ', f1)\n",
    "        print()\n",
    "    print('________________________________________________________________________________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50ba6122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature:  2\n",
      "Best Classifier:  RandomForestClassifier()\n",
      "Best Accuracy:  0.9782608695652174\n"
     ]
    }
   ],
   "source": [
    "# The best classifier-feature combination\n",
    "print('Best Feature: ', best_feature)\n",
    "print('Best Classifier: ', best_classifier)\n",
    "print('Best Accuracy: ', best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b263db7e",
   "metadata": {},
   "source": [
    "As depicted in above results, the highest accuracy(0.97) is obtained when the last 2 letters of a name is considered, combined with the Random Forest Classifier. When considersing other features, Both last letter and last 3 letters manage to obtain accuracies greater than 0.96. And also compared to Logistic Regression and Support Vector Machine classifiers, Decision Tree and Random forest classifiers perform well in this particular classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f690fe1",
   "metadata": {},
   "source": [
    "## Misclassifications of the best classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8900a5f",
   "metadata": {},
   "source": [
    "The best classifier identified above is used to make predictions on the test set and misclassified samples are identified. Finally, the misclassified samples are printed with its true label and predicted label of the best classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1408a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = convert_names_to_features(X_test, best_feature)\n",
    "\n",
    "pred = best_classifier.predict(X_test)\n",
    "# Identifying misclassified samples\n",
    "misclassified = np.where(pred != y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5268ce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------+\n",
      "| Misclassified Name | True Label | Prediction |\n",
      "+--------------------+------------+------------+\n",
      "|        ෆ්‍රෙඩී        |    male    |   female   |\n",
      "|        විශ්වා        |    male    |   female   |\n",
      "+--------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Misclassified Name\", \"True Label\", \"Prediction\"]\n",
    "\n",
    "for sample in misclassified[0]:\n",
    "    table.add_row((name_list.values[sample], y_test.values[sample], pred[sample]))\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a94a8d",
   "metadata": {},
   "source": [
    "## Feature Importance of the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14d2fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.07679\n",
      "Feature: 1, Score: 0.05707\n",
      "Feature: 2, Score: 0.08253\n",
      "Feature: 3, Score: 0.78361\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUv0lEQVR4nO3df5BdZ33f8fcnsj2EXwaj5UdkB6lUCVU8xoGtAgkNTgtEhjYygzvISQOmpBpnappMhwxqOyG0zrQ49EemwalGpR6TmRaVDgYECAylGDohpFoT2SAb0a1w8Ea0XiA1P+qJI/PtH/fIXK7v7j0r3dVdP3m/Zu7sOed57jnf+3j18dlz73luqgpJ0mPfD8y6AEnSdBjoktQIA12SGmGgS1IjDHRJasR5szrw5s2ba+vWrbM6vCQ9Jt1xxx1fq6q5cW0zC/StW7eysLAwq8NL0mNSkj9eqc1LLpLUiF6BnmRXkuNJFpPsG9N+YZIPJrkzybEkr59+qZKk1UwM9CSbgJuAK4EdwDVJdox0+/vA3VX1POAK4F8luWDKtUqSVtHnDH0nsFhVJ6rqIeAgsHukTwFPShLgicA3gFNTrVSStKo+gb4FuG9ofanbNuwdwF8BTgKfB36lqr47uqMke5MsJFlYXl4+w5IlSeP0CfSM2TY6o9fPAkeBHwIuB96R5MmPelLVgaqar6r5ubmxn7qRJJ2hPoG+BFwytH4xgzPxYa8Hbq2BReDLwHOnU6IkqY8+gX4E2J5kW/dG5x7g0EifrwB/AyDJM4AfBU5Ms1BJ0uom3lhUVaeSXA/cBmwCbq6qY0mu69r3AzcAtyT5PINLNG+uqq+tY92SpBG97hStqsPA4ZFt+4eWTwIvn25pklq1dd+HZ13CTN37tleuy369U1SSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiN6BXqSXUmOJ1lMsm9M+68lOdo9vpDk4SQXTb9cSdJKJgZ6kk3ATcCVwA7gmiQ7hvtU1dur6vKquhz4R8Cnquob61CvJGkFfc7QdwKLVXWiqh4CDgK7V+l/DfDuaRQnSeqvT6BvAe4bWl/qtj1KkscDu4D3rtC+N8lCkoXl5eW11ipJWkWfQM+YbbVC378F/P5Kl1uq6kBVzVfV/NzcXN8aJUk99An0JeCSofWLgZMr9N2Dl1skaSb6BPoRYHuSbUkuYBDah0Y7JbkQeAnwgemWKEnq47xJHarqVJLrgduATcDNVXUsyXVd+/6u66uAj1XVd9atWknSiiYGOkBVHQYOj2zbP7J+C3DLtAqTJK2Nd4pKUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSI3oFepJdSY4nWUyyb4U+VyQ5muRYkk9Nt0xJ0iQTv4IuySbgJuBlwBJwJMmhqrp7qM9TgN8FdlXVV5I8fZ3qlSStoM8Z+k5gsapOVNVDwEFg90ifnwduraqvAFTV/dMtU5I0SZ9A3wLcN7S+1G0b9iPAU5PcnuSOJK8dt6Mke5MsJFlYXl4+s4olSWP1CfSM2VYj6+cBLwBeCfws8OtJfuRRT6o6UFXzVTU/Nze35mIlSSubeA2dwRn5JUPrFwMnx/T5WlV9B/hOkk8DzwO+NJUqJUkT9TlDPwJsT7ItyQXAHuDQSJ8PAH8tyXlJHg/8BHDPdEuVJK1m4hl6VZ1Kcj1wG7AJuLmqjiW5rmvfX1X3JPkocBfwXeCdVfWF9SxckvT9+lxyoaoOA4dHtu0fWX878PbplSZJWgvvFJWkRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1IhegZ5kV5LjSRaT7BvTfkWSB5Ic7R5vmX6pkqTVTPxO0SSbgJuAlwFLwJEkh6rq7pGu/72q/uY61ChJ6qHPGfpOYLGqTlTVQ8BBYPf6liVJWqs+gb4FuG9ofanbNupFSe5M8pEkPzZuR0n2JllIsrC8vHwG5UqSVtIn0DNmW42sfw54dlU9D/gd4P3jdlRVB6pqvqrm5+bm1lSoJGl1fQJ9CbhkaP1i4ORwh6r6ZlV9u1s+DJyfZPPUqpQkTdQn0I8A25NsS3IBsAc4NNwhyTOTpFve2e3369MuVpK0somfcqmqU0muB24DNgE3V9WxJNd17fuBq4FfTnIKeBDYU1Wjl2UkSetoYqDDI5dRDo9s2z+0/A7gHdMtTZK0Ft4pKkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY3oFehJdiU5nmQxyb5V+v3VJA8nuXp6JUqS+pgY6Ek2ATcBVwI7gGuS7Fih340MvntUknSO9TlD3wksVtWJqnoIOAjsHtPvjcB7gfunWJ8kqac+gb4FuG9ofanb9ogkW4BXAftZRZK9SRaSLCwvL6+1VknSKvoEesZsq5H13wbeXFUPr7ajqjpQVfNVNT83N9ezRElSH+f16LMEXDK0fjFwcqTPPHAwCcBm4BVJTlXV+6dRpCRpsj6BfgTYnmQb8CfAHuDnhztU1bbTy0luAT5kmEvSuTUx0KvqVJLrGXx6ZRNwc1UdS3Jd177qdXNJ0rnR5wydqjoMHB7ZNjbIq+rasy9LkrRW3ikqSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjegV6El2JTmeZDHJvjHtu5PcleRokoUkL55+qZKk1Uz8Crokm4CbgJcBS8CRJIeq6u6hbp8ADlVVJbkMeA/w3PUoWJI0Xp8z9J3AYlWdqKqHgIPA7uEOVfXtqqpu9QlAIUk6p/oE+hbgvqH1pW7b90nyqiRfBD4M/N3plCdJ6qtPoGfMtkedgVfV+6rqucBVwA1jd5Ts7a6xLywvL6+pUEnS6voE+hJwydD6xcDJlTpX1aeB5yTZPKbtQFXNV9X83NzcmouVJK2sT6AfAbYn2ZbkAmAPcGi4Q5K/nCTd8vOBC4CvT7tYSdLKJn7KpapOJbkeuA3YBNxcVceSXNe17wdeDbw2yZ8DDwKvGXqTVJJ0DkwMdICqOgwcHtm2f2j5RuDG6ZYmSVoL7xSVpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktSIXoGeZFeS40kWk+wb0/4LSe7qHp9J8rzplypJWs3EQE+yCbgJuBLYAVyTZMdIty8DL6mqy4AbgAPTLlSStLo+Z+g7gcWqOlFVDwEHgd3DHarqM1X1p93qZ4GLp1umJGmSPoG+BbhvaH2p27aSNwAfGdeQZG+ShSQLy8vL/auUJE3UJ9AzZluN7Zj8DINAf/O49qo6UFXzVTU/NzfXv0pJ0kTn9eizBFwytH4xcHK0U5LLgHcCV1bV16dTniSprz5n6EeA7Um2JbkA2AMcGu6Q5IeBW4FfrKovTb9MSdIkE8/Qq+pUkuuB24BNwM1VdSzJdV37fuAtwNOA300CcKqq5tevbEnSqD6XXKiqw8DhkW37h5Z/Cfil6ZYmSVoL7xSVpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRvQK9CS7khxPsphk35j25yb5gyR/luRN0y9TkjTJxK+gS7IJuAl4GbAEHElyqKruHur2DeAfAFetR5GSpMn6nKHvBBar6kRVPQQcBHYPd6iq+6vqCPDn61CjJKmHPoG+BbhvaH2p27ZmSfYmWUiysLy8fCa7kCStoE+gZ8y2OpODVdWBqpqvqvm5ubkz2YUkaQV9An0JuGRo/WLg5PqUI0k6U30C/QiwPcm2JBcAe4BD61uWJGmtJn7KpapOJbkeuA3YBNxcVceSXNe170/yTGABeDLw3SS/Cuyoqm+uX+mSpGETAx2gqg4Dh0e27R9a/t8MLsVIfyFs3ffhWZcwU/e+7ZWzLkFjeKeoJDWi1xn6RuPZkWdHkh7NM3RJaoSBLkmNMNAlqREGuiQ14jH5pqjOnm8s+8ay2uMZuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1IhegZ5kV5LjSRaT7BvTniT/tmu/K8nzp1+qJGk1EwM9ySbgJuBKYAdwTZIdI92uBLZ3j73Av5tynZKkCfqcoe8EFqvqRFU9BBwEdo/02Q38Xg18FnhKkmdNuVZJ0ir6TJ+7BbhvaH0J+IkefbYAXx3ulGQvgzN4gG8nOb7CMTcDX+tR26zMtL7c2KubY7iKHmPo+K3C8Ts7Zzl+z17pSX0CPWO21Rn0oaoOAAcmHjBZqKr5HrXNxEavDzZ+jdZ3dqzv7LRaX59LLkvAJUPrFwMnz6CPJGkd9Qn0I8D2JNuSXADsAQ6N9DkEvLb7tMsLgQeq6qujO5IkrZ+Jl1yq6lSS64HbgE3AzVV1LMl1Xft+4DDwCmAR+H/A68+yromXZWZso9cHG79G6zs71nd2mqwvVY+61C1JegzyTlFJaoSBLkmN2BCBnuSiJB9P8j+7n09dod+9ST6f5GiShXNQ14ae8qBHfVckeaAbr6NJ3nKO67s5yf1JvrBC+6zHb1J9Mxu/JJck+WSSe5IcS/IrY/rMbPx61jfL8Xtckv+R5M6uvn86ps+sf//61Li2MayqmT+A3wL2dcv7gBtX6HcvsPkc1bQJ+F/AXwIuAO4Edoz0eQXwEQafw38h8IfncMz61HcF8KEZ/nf9aeD5wBdWaJ/Z+PWsb2bjBzwLeH63/CTgSxvs969PfbMcvwBP7JbPB/4QeOFGGb811LimMdwQZ+gMpg54V7f8LuCq2ZXyiI0+5UGf+maqqj4NfGOVLjOdMqJHfTNTVV+tqs91y98C7mFw9/WwmY1fz/pmphuTb3er53eP0U+AzPr3r0+Na7JRAv0Z1X1uvfv59BX6FfCxJHd00wisp5WmM1hrn/XS99gv6v6k+0iSHzs3pfU2y/Hra+bjl2Qr8OMMzuCGbYjxW6U+mOH4JdmU5ChwP/Dxqtpw49ejRljDGPa59X8qkvxX4Jljmv7JGnbzU1V1MsnTgY8n+WJ3lrUepjblwTrpc+zPAc+uqm8neQXwfgYzYm4Usxy/PmY+fkmeCLwX+NWq+uZo85innNPxm1DfTMevqh4GLk/yFOB9SS6tquH3S2Y+fj1qXNMYnrMz9Kp6aVVdOubxAeD/nP5Tp/t5/wr7ONn9vB94H4PLDutlo095MPHYVfXN03/SVdVh4Pwkm89RfX1s6CkjZj1+Sc5nEJb/sapuHdNlpuM3qb5Zj99QHf8XuB3YNdK0YX7/VqpxrWO4US65HAJe1y2/DvjAaIckT0jypNPLwMuBsZ9OmJKNPuXBxPqSPDNJuuWdDP57f/0c1dfHhp4yYpbj1x33PwD3VNW/XqHbzMavT30zHr+57qyXJD8IvBT44ki3mf7+9alxrWN4zi65TPA24D1J3gB8BfjbAEl+CHhnVb0CeAaDP0lgUPd/qqqPrldBNZspD6Zd39XALyc5BTwI7KnurfNzIcm7GbxLvznJEvAbDN74mfn49axvluP3U8AvAp/vrrEC/GPgh4fqm+X49alvluP3LOBdGXxBzw8A76mqD22Uf79rqHFNY+it/5LUiI1yyUWSdJYMdElqhIEuSY0w0CWpEQa6JDXCQNe6SPJwvjdD3NHu9vC17uOqJDvWoTySbM0KsyyulySXd3f7Setio3wOXe15sKouP8t9XAV8CLi77xOSnFdVp87yuFOX5DzgcmCeweefpanzDF3nTJIXJPlUBpOr3TY03cPfS3Kkm4DovUken+QngZ8D3t6d4T8nye1J5rvnbE5yb7d8bZL/kuSDDCZve0IGc50fSfJHSVadhbJ7/vuTfDDJl5Ncn+Qfds/9bJKLun63J/ntJJ9J8oXuzr3T8/m/P4M5tT+b5LJu+1uTHEjyMeD3gH8GvKZ7Pa9JsrPb1x91P390qJ5bk3w0g+8I+K2hWncl+Vw3Vp/otq3p9aphk+bX9eHjTB7Aw8DR7vE+BndgfgaY69pfw+DuVoCnDT3vN4E3dsu3AFcPtd0OzHfLm4F7u+VrGczLcVG3/s+Bv9MtP4XBXN1PGKlvK9086N3zFxnM6z0HPABc17X9GwYTT50+/r/vln966Pm/A/xGt/zXgaPd8luBO4AfHDrOO4ZqeDJwXrf8UuC9Q/1OABcCjwP+mMGcI3MMZgfc1vXr/Xp9/MV4eMlF6+X7LrkkuRS4lMEsmTCYruD0vBmXJvlNBmH0RAbTGazVx6vq9NzmLwd+LsmbuvXHMbgl/Z5Vnv/JGszr/a0kDwAf7LZ/HrhsqN+7YTCXepInd3NxvBh4dbf9vyV5WpILu/6HqurBFY55IYNbv7czmOXv/KG2T1TVAwBJ7gaeDTwV+HRVfbk71tm8XjXIQNe5EuBYVb1oTNstwFVVdWeSaxnMrzLOKb53mfBxI23fGTnWq6vq+Brq+7Oh5e8OrX+X7/93MjpXRrH6NKzfGdN22g0M/kfyqu5N49tXqOfhroaMOT6c2etVg7yGrnPlODCX5EUwmHo135us/0nAVzOYjvUXhp7zra7ttHuBF3TLV69yrNuANyaPzFL342df/iNe0+3zxQxm53sA+DRd3UmuAL5Wj54bHB79ei4E/qRbvrbHsf8AeEmSbd2xLuq2r+fr1WOIga5zogZfk3c1cGOSOxlcW//JrvnXGXzbzcf5/ulDDwK/1r3R9xzgXzKYee4zDK6hr+QGBpcv7uo+mnjDFF/Kn3bH3w+8odv2VmA+yV0MZg593QrP/SSw4/Sbogy+S/dfJPl9BpegVlVVy8Be4NZuDP9z17Ser1ePIc62KPWU5HbgTVW1MOtapHE8Q5ekRniGLkmN8AxdkhphoEtSIwx0SWqEgS5JjTDQJakR/x90L/uayVEKRAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deriving important features\n",
    "imp = best_classifier.feature_importances_\n",
    "\n",
    "# printing the important features with their importance\n",
    "for f, s in enumerate(imp):\n",
    "    print('Feature: %0d, Score: %.5f' % (f, s))\n",
    "    \n",
    "# plotting the graph    \n",
    "plt.bar([x for x in range(len(imp))], imp)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127b9d9",
   "metadata": {},
   "source": [
    "The best classification accuracy is obtained when the last 2 letters are considered. As mentioned in the beginning of this notebook, each letter is represented by two unicode characters. Therefore this particular dataset contains 4 features. The above chart representing the feature importance show that the most impotant feature in this classification is the 4th feature, which is the diacritic of the last letter. \n",
    "\n",
    "When looking at the misclassifications of the model, we can see that 2 letters containing 'Diga ispilla(දිග ඉස්පිල්ල)' and 'Ælapilla(\tඇලපිල්ල)' as the final diacritic have been misclassified as female. It is in fact very common for sinhala female names to end with these diacritics. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
